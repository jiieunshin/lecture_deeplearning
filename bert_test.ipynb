{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10ymBAZZFbMOOFPOvfPhDtvtu_QlBn7HO",
      "authorship_tag": "ABX9TyP7xn8ne75MYmetJqFdyZnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eec8c2b01c20426e90017611de17c7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7f0756034a9468daf5d5e5ed5a5bf09",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef498a0cb2d64e73b6f959c6efe94987",
              "IPY_MODEL_1fe536260c6049f9ab800060cabff9da"
            ]
          }
        },
        "e7f0756034a9468daf5d5e5ed5a5bf09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef498a0cb2d64e73b6f959c6efe94987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f47dbb21d9f4cf3b131745cc910adcd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_488b4d4a5c5e4f48a85fe0ccc5091eb9"
          }
        },
        "1fe536260c6049f9ab800060cabff9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad88c104edc5423a974c3ef45d770e77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:05&lt;00:00,  2.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d216734332164f21a26a51fba58510e9"
          }
        },
        "4f47dbb21d9f4cf3b131745cc910adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "488b4d4a5c5e4f48a85fe0ccc5091eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad88c104edc5423a974c3ef45d770e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d216734332164f21a26a51fba58510e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiieunshin/lecture_deeplearning/blob/master/bert_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMhPZ93iVzhb",
        "outputId": "506596a9-d915-49f5-f4a7-01e5baecbbc0"
      },
      "source": [
        "# 이는 구글 코랩으로 돌린 버전입니다. 그리고 기본 코드는 SKT Brain의 KoBERT를 그대로 가져왔고, 학습 및 테스트 데이터셋만 따로 준비한 것입니다.\n",
        "# SKT Brain github 주소는 다음과 같습니다. https://github.com/SKTBrain/KoBERT\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 # 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-qf7gzqi4\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-qf7gzqi4\n",
            "Requirement already satisfied (use --upgrade to upgrade): kobert==0.1.2 from git+https://****@github.com/SKTBrain/KoBERT.git@master in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12718 sha256=bc4319b1a52877d3c4086b720e7c8c598303c1ddab18a856f6293b990064879c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lra9njrd/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYBOVHaV9rj"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uDu2nyeV91v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc212fd-acf6-4a6f-ee25-4935bbf78928"
      },
      "source": [
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajacOpoU3K_W"
      },
      "source": [
        "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        " \n",
        "# from pykospacing import Spacing\n",
        "# import re \n",
        "\n",
        "# save_text = []\n",
        "# for idx, contents in enumerate(train_data['내용']):\n",
        "#     pre_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", contents) \n",
        "#     spacing = Spacing()\n",
        "#     save_text.append(spacing(pre_text)) \n",
        " \n",
        "# train_data['내용2'] = save_text\n",
        "# train_data  \n",
        " \n",
        "# word_cnt = train_data['내용2'].astype(str).apply(lambda x:len(x.split(' ')))\n",
        "# train_data['word_cnt'] = word_cnt\n",
        " \n",
        "# drop_ind=[]\n",
        "# for ind, cnt in enumerate(train_data['word_cnt']):\n",
        "#     if cnt <= 10:\n",
        "#         drop_ind.append(ind)\n",
        " \n",
        "# train_data.drop(train_data.index[drop_ind], inplace=True)\n",
        "# train_data  \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxhNx183fgE"
      },
      "source": [
        "# save_text = []\n",
        "# for idx, contents in enumerate(test_data['내용']):\n",
        "#     pre_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", contents) \n",
        "#     spacing = Spacing()\n",
        "#     save_text.append(spacing(pre_text)) \n",
        " \n",
        "# test_data['내용2'] = save_text\n",
        "# test_data  \n",
        " \n",
        "# word_cnt = test_data['내용2'].astype(str).apply(lambda x:len(x.split(' ')))\n",
        "# test_data['word_cnt'] = word_cnt\n",
        " \n",
        "# drop_ind=[]\n",
        "# for ind, cnt in enumerate(test_data['word_cnt']):\n",
        "#     if cnt <= 10:\n",
        "#         drop_ind.append(ind)\n",
        " \n",
        "# test_data.drop(test_data.index[drop_ind], inplace=True)\n",
        "# test_data  \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFV_c3bnYGY8"
      },
      "source": [
        "# train_data.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/re_train_data.csv', header = True, index = False)\n",
        "# test_data.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/re_test_data.csv', header = True, index = False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKNmi4KRXtIW"
      },
      "source": [
        "# 학습용 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/re_train_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/re_test_data.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbggZajDob7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c477d8-5bb1-4492-ad1d-84360f0e0ae0"
      },
      "source": [
        "train_data['카테고리'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    1825\n",
              "4    1777\n",
              "2    1430\n",
              "1    1326\n",
              "0    1146\n",
              "Name: 카테고리, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO6yiZSjxKM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c487938-c392-4ba2-e617-43212219b6a8"
      },
      "source": [
        "train_data[\"내용2\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       네 이번 뉴스를 보다 너무 어 이가 없어서 청원을 올립니 다 하루가 멀다 하고 올라...\n",
              "1       안녕하세요 세 발달 지연 아이를 키우고 있는 대한민국의 평범한 어머니입니다 제가 청...\n",
              "2       년전의 일이고 고소를 취하한 내용이지만 이자매가 그 일로 인해 자살하고 아버지마저 ...\n",
              "3       은혜로 목사인 신 목사에게 꼬임을 당해 끌려간 사람들을 구하고 신 목사와 그 주변에...\n",
              "4       최근 주 사이 우동기 대구시교육감에 대한 생각을 적지 않을 수 없어 몇 자 적습니다...\n",
              "                              ...                        \n",
              "7499    대입 수험생을 둔 가정에서 많은 분들이 아쉬워하는 교육과정평가원의 수능 및 모의평가...\n",
              "7500    이번 국회의원 피기감 기관 지원과 관련 전수조사하여 잘못된 관행을 바로잡았으면 합니...\n",
              "7501    울진 한울원전 호기는 상업운전 초기부터 심각한 전열관 손상이 있었습니다 그리고 년간...\n",
              "7502    여러분 혹시 지금 서남대학교 폐교에 대한 기사를 보셨나요 죽전캠 분들에겐 해 당 사...\n",
              "7503    이런 귀 중 한 문제는 만이 넘어가야 청원 승락되는 것에서 좀 컷트라인을 낮춰서 다...\n",
              "Name: 내용2, Length: 7504, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgmlInVOqrxH"
      },
      "source": [
        "# 라벨링된 카테고리명 매핑 ex) {0: '경제민주화', 1: '교통/건축/국토', 2: '기타',3: '농산어촌', 4: '문화/예술/체육/언론'}\n",
        "# mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "# mapping"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tnjBQyWqrzX"
      },
      "source": [
        "# Train / Test set 분리\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# print(\"train shape is:\", len(train))\n",
        "# print(\"test shape is:\", len(test))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evkql3cLslwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2922c70-53e5-4c1a-f82b-c04bd8a27cfa"
      },
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwrMvpIwslyu"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "        self.sentences = [transform(i) for i in dataset['내용']]\n",
        "        self.labels = [np.int32(i) for i in dataset['카테고리']]\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBjAZ1vBsl06"
      },
      "source": [
        "# Setting parameters\n",
        "np.random.seed(1234)\n",
        "max_len = 50 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 124\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0gaiEKJsl3E"
      },
      "source": [
        "bert_train = BERTDataset(train_data, tok, max_len, True, False)\n",
        "bert_test = BERTDataset(test_data, tok, max_len, True, False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfI2d9Us0xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba53e40-5dc5-46ec-c635-61c224da6219"
      },
      "source": [
        "print(bert_train)\n",
        "print(bert_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.BERTDataset object at 0x7f01a154c550>\n",
            "<__main__.BERTDataset object at 0x7f01a19485d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUZpwfss01C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8a2801-c99f-45ac-a6d3-bf40c9377406"
      },
      "source": [
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = torch.utils.data.DataLoader(bert_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(bert_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFpr9Jrpz0wO"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 14,\n",
        "                 num_classes = 5, # softmax 사용 <- binary일 경우는 2\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_sEvyKz0yZ"
      },
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU1HjIZyz00V"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147jQgU0s03m"
      },
      "source": [
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BoKbUrvs05i"
      },
      "source": [
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()\n",
        "    return train_acc\n",
        "# /max_indices.size()[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnfdhBTdCBV"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# for e in range(num_epochs):\n",
        "#     train_acc = 0.0\n",
        "#     # test_acc = 0.0\n",
        "#     model.train()\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length= valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "#         loss = loss_fn(out, label)\n",
        "#         loss.backward\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()  # Update learning rate schedule\n",
        "#         train_acc += calc_accuracy(out, label)\n",
        "#         if batch_id % log_interval == 0:\n",
        "#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (7847)))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAtApdA8g_OA"
      },
      "source": [
        "# test"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMT-As8LdIMd"
      },
      "source": [
        "# unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['제목', '카테고리']])\n",
        "# unseen_values = unseen_test.values\n",
        "# test_set = BERTDataset(unseen_values, 0, 1, tok, max_len, True, False)\n",
        "# test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3571O8GmSR_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97233a96-1c59-4521-c057-c69dc6cd6c4f"
      },
      "source": [
        "test_input = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daha6rpBSZtD"
      },
      "source": [
        "# BERTDataset(unseen_values, tok, max_len, True, False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRyY4xbkh0te"
      },
      "source": [
        "# tqdm_notebook(test_input)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsI9S62hoHg"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# test_acc = 0.0\n",
        "# for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "#   optimizer.zero_grad()\n",
        "#   token_ids = token_ids.long().to(device)\n",
        "#   segment_ids = segment_ids.long().to(device)\n",
        "#   valid_length= valid_length\n",
        "#   label = label.long().to(device)\n",
        "#   out = model(token_ids, valid_length, segment_ids)\n",
        "#   loss = loss_fn(out, label)\n",
        "#   loss.backward\n",
        "#   torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#   optimizer.step()\n",
        "#   scheduler.step()  # Update learning rate schedule\n",
        "#   test_acc += calc_accuracy(out, label)\n",
        "#   if batch_id % log_interval == 0:\n",
        "#     print(\"batch id {} loss {} test acc {}\".format(batch_id+1, loss.data.cpu().numpy(), test_acc / (batch_id+1)))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWE4YbtrNB19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8f1214-7135-43bb-d9a8-3961f466b1da"
      },
      "source": [
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id == batch_size :\n",
        "          print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id + 1)))    \n",
        "    \n",
        "# "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/61 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 61/61 [00:20<00:00,  2.96it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 23.098360655737704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:20<00:00,  2.93it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 22.60655737704918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:21<00:00,  2.87it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 22.40983606557377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:21<00:00,  2.82it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train acc 23.0327868852459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:21<00:00,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train acc 22.83606557377049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZZddjvPFjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "eec8c2b01c20426e90017611de17c7c2",
            "e7f0756034a9468daf5d5e5ed5a5bf09",
            "ef498a0cb2d64e73b6f959c6efe94987",
            "1fe536260c6049f9ab800060cabff9da",
            "4f47dbb21d9f4cf3b131745cc910adcd",
            "488b4d4a5c5e4f48a85fe0ccc5091eb9",
            "ad88c104edc5423a974c3ef45d770e77",
            "d216734332164f21a26a51fba58510e9"
          ]
        },
        "outputId": "201534ef-d21f-443d-eb8a-a2d4f507e9f1"
      },
      "source": [
        "model.eval() # 평가 모드로 변경\n",
        "test_acc = 0.0\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  label = label.long().to(device)\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  test_acc += calc_accuracy(out, label)\n",
        "  print(\"test acc {}\".format(test_acc / (batch_id+1)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eec8c2b01c20426e90017611de17c7c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc 16.0\n",
            "test acc 16.5\n",
            "test acc 20.0\n",
            "test acc 20.75\n",
            "test acc 21.6\n",
            "test acc 21.166666666666668\n",
            "test acc 20.714285714285715\n",
            "test acc 20.375\n",
            "test acc 20.77777777777778\n",
            "test acc 21.2\n",
            "test acc 21.0\n",
            "test acc 21.333333333333332\n",
            "test acc 21.692307692307693\n",
            "test acc 21.928571428571427\n",
            "test acc 21.533333333333335\n",
            "test acc 20.6875\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK94hstwJ-AK"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}