{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10ymBAZZFbMOOFPOvfPhDtvtu_QlBn7HO",
      "authorship_tag": "ABX9TyPhZkUR3qKiN0a0rE9cKA03",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cc3a09aad3e466abf985fcb404f1942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b1d7eed60284ae9888672a7408a89cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95a2075103e34e5c87dffdc44cb06bd4",
              "IPY_MODEL_292ec299f69f4bd7b56c157fd6cd1b64"
            ]
          }
        },
        "2b1d7eed60284ae9888672a7408a89cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95a2075103e34e5c87dffdc44cb06bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6bfc9b0378644d1a86dd7dec8a4afaf4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a2fdbd3f2fd464f9e21157c1b98e951"
          }
        },
        "292ec299f69f4bd7b56c157fd6cd1b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f53063de4e8d48778e4c87e69004458f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:07&lt;00:00,  2.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8c898bf1d1446d89c2b37a79acafd44"
          }
        },
        "6bfc9b0378644d1a86dd7dec8a4afaf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a2fdbd3f2fd464f9e21157c1b98e951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f53063de4e8d48778e4c87e69004458f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8c898bf1d1446d89c2b37a79acafd44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiieunshin/lecture_deeplearning/blob/master/bert_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMhPZ93iVzhb",
        "outputId": "a809cbb6-423e-4c15-9c7d-d6a0d68dee09"
      },
      "source": [
        "# 이는 구글 코랩으로 돌린 버전입니다. 그리고 기본 코드는 SKT Brain의 KoBERT를 그대로 가져왔고, 학습 및 테스트 데이터셋만 따로 준비한 것입니다.\n",
        "# SKT Brain github 주소는 다음과 같습니다. https://github.com/SKTBrain/KoBERT\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 # 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595700 sha256=e6a860e802659f1a0f16ff6af932a048c499471c9ba378ba5d823abdb398f977\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 19.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 25.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-xexu29px\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-xexu29px\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12773 sha256=6b75884e749d644589eec189854a04b650ce3741ac031cec1814aa4c2e7b2d0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9mpexnha/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYBOVHaV9rj"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uDu2nyeV91v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f78117-79df-42b1-da4c-9fd4c17be826"
      },
      "source": [
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajacOpoU3K_W"
      },
      "source": [
        "# !pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        " \n",
        "# from pykospacing import Spacing\n",
        "# import re \n",
        "\n",
        "# save_text = []\n",
        "# for idx, contents in enumerate(train_data['내용']):\n",
        "#     pre_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", contents) \n",
        "#     spacing = Spacing()\n",
        "#     save_text.append(spacing(pre_text)) \n",
        " \n",
        "# train_data['내용2'] = save_text\n",
        "# train_data  \n",
        " \n",
        "# word_cnt = train_data['내용2'].astype(str).apply(lambda x:len(x.split(' ')))\n",
        "# train_data['word_cnt'] = word_cnt\n",
        " \n",
        "# drop_ind=[]\n",
        "# for ind, cnt in enumerate(train_data['word_cnt']):\n",
        "#     if cnt <= 10:\n",
        "#         drop_ind.append(ind)\n",
        " \n",
        "# train_data.drop(train_data.index[drop_ind], inplace=True)\n",
        "# train_data  \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxhNx183fgE"
      },
      "source": [
        "# save_text = []\n",
        "# for idx, contents in enumerate(test_data['내용']):\n",
        "#     pre_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", contents) \n",
        "#     spacing = Spacing()\n",
        "#     save_text.append(spacing(pre_text)) \n",
        " \n",
        "# test_data['내용2'] = save_text\n",
        "# test_data  \n",
        " \n",
        "# word_cnt = test_data['내용2'].astype(str).apply(lambda x:len(x.split(' ')))\n",
        "# test_data['word_cnt'] = word_cnt\n",
        " \n",
        "# drop_ind=[]\n",
        "# for ind, cnt in enumerate(test_data['word_cnt']):\n",
        "#     if cnt <= 10:\n",
        "#         drop_ind.append(ind)\n",
        " \n",
        "# test_data.drop(test_data.index[drop_ind], inplace=True)\n",
        "# test_data  \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwfHg8Sqieso"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFV_c3bnYGY8"
      },
      "source": [
        "# train_data.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/re_train_data.csv', header = True, index = False)\n",
        "# test_data.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/re_test_data.csv', header = True, index = False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKNmi4KRXtIW"
      },
      "source": [
        "# 학습용 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/re_train_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/re_test_data.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbggZajDob7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe7a1a2-22f1-42a7-d40d-7dc311cc4d8e"
      },
      "source": [
        "train_data['카테고리'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    1825\n",
              "4    1777\n",
              "2    1430\n",
              "1    1326\n",
              "0    1146\n",
              "Name: 카테고리, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGDOw5jIxr0s",
        "outputId": "bf49c22e-ad7c-418e-a551-cccc65d1952f"
      },
      "source": [
        "test_data['카테고리'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    443\n",
              "3    442\n",
              "2    393\n",
              "1    318\n",
              "0    294\n",
              "Name: 카테고리, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX0Vi6D2bJpp"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO6yiZSjxKM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae8d5f3-bced-4e8a-f576-afa1bd1ec704"
      },
      "source": [
        "train_data[\"내용2\"]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       네 이번 뉴스를 보다 너무 어 이가 없어서 청원을 올립니 다 하루가 멀다 하고 올라...\n",
              "1       안녕하세요 세 발달 지연 아이를 키우고 있는 대한민국의 평범한 어머니입니다 제가 청...\n",
              "2       년전의 일이고 고소를 취하한 내용이지만 이자매가 그 일로 인해 자살하고 아버지마저 ...\n",
              "3       은혜로 목사인 신 목사에게 꼬임을 당해 끌려간 사람들을 구하고 신 목사와 그 주변에...\n",
              "4       최근 주 사이 우동기 대구시교육감에 대한 생각을 적지 않을 수 없어 몇 자 적습니다...\n",
              "                              ...                        \n",
              "7499    대입 수험생을 둔 가정에서 많은 분들이 아쉬워하는 교육과정평가원의 수능 및 모의평가...\n",
              "7500    이번 국회의원 피기감 기관 지원과 관련 전수조사하여 잘못된 관행을 바로잡았으면 합니...\n",
              "7501    울진 한울원전 호기는 상업운전 초기부터 심각한 전열관 손상이 있었습니다 그리고 년간...\n",
              "7502    여러분 혹시 지금 서남대학교 폐교에 대한 기사를 보셨나요 죽전캠 분들에겐 해 당 사...\n",
              "7503    이런 귀 중 한 문제는 만이 넘어가야 청원 승락되는 것에서 좀 컷트라인을 낮춰서 다...\n",
              "Name: 내용2, Length: 7504, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgmlInVOqrxH"
      },
      "source": [
        "# 라벨링된 카테고리명 매핑 ex) {0: '경제민주화', 1: '교통/건축/국토', 2: '기타',3: '농산어촌', 4: '문화/예술/체육/언론'}\n",
        "# mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "# mapping"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tnjBQyWqrzX"
      },
      "source": [
        "# Train / Test set 분리\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# print(\"train shape is:\", len(train))\n",
        "# print(\"test shape is:\", len(test))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNM9Cn3CekXC"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evkql3cLslwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015adb4b-e667-4468-e853-8fe43356944f"
      },
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwrMvpIwslyu"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "        self.sentences = [transform(i) for i in dataset['내용2']]\n",
        "        self.labels = [np.int32(i) for i in dataset['카테고리']]\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjBrOHGCiBGy"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drWU8s9Xjetd"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBjAZ1vBsl06"
      },
      "source": [
        "# Setting parameters\n",
        "np.random.seed(1234)\n",
        "max_len = 30 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 124\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0gaiEKJsl3E"
      },
      "source": [
        "bert_train = BERTDataset(train_data, tok, max_len, True, False)\n",
        "bert_test = BERTDataset(test_data, tok, max_len, True, False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfI2d9Us0xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a871516c-b2b9-498d-9f46-5050827f650f"
      },
      "source": [
        "print(bert_train)\n",
        "print(bert_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.BERTDataset object at 0x7f483ca9e4d0>\n",
            "<__main__.BERTDataset object at 0x7f4840c69890>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUZpwfss01C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a597d205-cb80-4f1d-dc1b-a5f9379ba83f"
      },
      "source": [
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = torch.utils.data.DataLoader(bert_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(bert_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFpr9Jrpz0wO"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 18,\n",
        "                 num_classes = 5, # softmax 사용 <- binary일 경우는 2\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_sEvyKz0yZ"
      },
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.2).to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU1HjIZyz00V"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147jQgU0s03m"
      },
      "source": [
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BoKbUrvs05i"
      },
      "source": [
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()\n",
        "    return train_acc\n",
        "# /max_indices.size()[0]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnfdhBTdCBV"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# for e in range(num_epochs):\n",
        "#     train_acc = 0.0\n",
        "#     # test_acc = 0.0\n",
        "#     model.train()\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length= valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "#         loss = loss_fn(out, label)\n",
        "#         loss.backward\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()  # Update learning rate schedule\n",
        "#         train_acc += calc_accuracy(out, label)\n",
        "#         if batch_id % log_interval == 0:\n",
        "#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (7847)))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAtApdA8g_OA"
      },
      "source": [
        "# test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMT-As8LdIMd"
      },
      "source": [
        "# unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['제목', '카테고리']])\n",
        "# unseen_values = unseen_test.values\n",
        "# test_set = BERTDataset(unseen_values, 0, 1, tok, max_len, True, False)\n",
        "# test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3571O8GmSR_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a063489-d3ea-4f24-bbe3-2e9ab2cc1d7a"
      },
      "source": [
        "test_input = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daha6rpBSZtD"
      },
      "source": [
        "# BERTDataset(unseen_values, tok, max_len, True, False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRyY4xbkh0te"
      },
      "source": [
        "# tqdm_notebook(test_input)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsI9S62hoHg"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# test_acc = 0.0\n",
        "# for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "#   optimizer.zero_grad()\n",
        "#   token_ids = token_ids.long().to(device)\n",
        "#   segment_ids = segment_ids.long().to(device)\n",
        "#   valid_length= valid_length\n",
        "#   label = label.long().to(device)\n",
        "#   out = model(token_ids, valid_length, segment_ids)\n",
        "#   loss = loss_fn(out, label)\n",
        "#   loss.backward\n",
        "#   torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#   optimizer.step()\n",
        "#   scheduler.step()  # Update learning rate schedule\n",
        "#   test_acc += calc_accuracy(out, label)\n",
        "#   if batch_id % log_interval == 0:\n",
        "#     print(\"batch id {} loss {} test acc {}\".format(batch_id+1, loss.data.cpu().numpy(), test_acc / (batch_id+1)))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWE4YbtrNB19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29efdbe3-7e34-45c7-edc3-ca586ca7ef1e"
      },
      "source": [
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id == batch_size :\n",
        "          print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id + 1)))    \n",
        "    \n",
        "# "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/61 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 61/61 [00:26<00:00,  2.27it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 21.950819672131146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:27<00:00,  2.24it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 21.459016393442624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:27<00:00,  2.23it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 21.459016393442624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:27<00:00,  2.23it/s]\n",
            "  0%|          | 0/61 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train acc 21.57377049180328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61/61 [00:27<00:00,  2.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train acc 21.770491803278688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZZddjvPFjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "8cc3a09aad3e466abf985fcb404f1942",
            "2b1d7eed60284ae9888672a7408a89cc",
            "95a2075103e34e5c87dffdc44cb06bd4",
            "292ec299f69f4bd7b56c157fd6cd1b64",
            "6bfc9b0378644d1a86dd7dec8a4afaf4",
            "0a2fdbd3f2fd464f9e21157c1b98e951",
            "f53063de4e8d48778e4c87e69004458f",
            "e8c898bf1d1446d89c2b37a79acafd44"
          ]
        },
        "outputId": "e755d505-014b-4b33-b7a8-b8527aaa0520"
      },
      "source": [
        "model.eval() # 평가 모드로 변경\n",
        "test_acc = 0.0\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  label = label.long().to(device)\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  test_acc += calc_accuracy(out, label)\n",
        "  print(\"test acc {}\".format(test_acc / (batch_id+1)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cc3a09aad3e466abf985fcb404f1942",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc 27.0\n",
            "test acc 24.0\n",
            "test acc 25.666666666666668\n",
            "test acc 27.5\n",
            "test acc 26.2\n",
            "test acc 25.5\n",
            "test acc 25.285714285714285\n",
            "test acc 25.625\n",
            "test acc 25.444444444444443\n",
            "test acc 26.1\n",
            "test acc 26.454545454545453\n",
            "test acc 26.0\n",
            "test acc 25.76923076923077\n",
            "test acc 25.571428571428573\n",
            "test acc 25.266666666666666\n",
            "test acc 23.875\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYteUkb2o-MN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK94hstwJ-AK"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}