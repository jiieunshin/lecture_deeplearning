{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10ymBAZZFbMOOFPOvfPhDtvtu_QlBn7HO",
      "authorship_tag": "ABX9TyN6bG61/U7oZ3dIby5Y4RHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a0284cc2e234434a24b856a0c8cfcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08c07aeff70044299585bfd7c4d7fd14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95b4543cbabd42d591fae4aa388ce49e",
              "IPY_MODEL_f693c537590a41c8ba33a560ac085374"
            ]
          }
        },
        "08c07aeff70044299585bfd7c4d7fd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95b4543cbabd42d591fae4aa388ce49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9508e3a861b04e5f9adf6610f71e9b23",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df8964880c4a4e4a9ba03998ab8ee25f"
          }
        },
        "f693c537590a41c8ba33a560ac085374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54b1b5e0f8264355b4437d25e880552e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:04&lt;00:00,  3.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2b774c87f03459cbdc1330b6bbcdd8c"
          }
        },
        "9508e3a861b04e5f9adf6610f71e9b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df8964880c4a4e4a9ba03998ab8ee25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54b1b5e0f8264355b4437d25e880552e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2b774c87f03459cbdc1330b6bbcdd8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiieunshin/lecture_deeplearning/blob/master/bert_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMhPZ93iVzhb",
        "outputId": "3e907024-dd2b-4c42-cd50-648db4bff6f9"
      },
      "source": [
        "# 이는 구글 코랩으로 돌린 버전입니다. 그리고 기본 코드는 SKT Brain의 KoBERT를 그대로 가져왔고, 학습 및 테스트 데이터셋만 따로 준비한 것입니다.\n",
        "# SKT Brain github 주소는 다음과 같습니다. https://github.com/SKTBrain/KoBERT\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 # 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595699 sha256=6e7f87fa3f3325295ad738937278cec49b490162e583b893cd94e38f95a52230\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-i1jt6h12\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-i1jt6h12\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12718 sha256=1f9470664791abed9db80b8c864f039b56155dab92c129c36ea16314f1d5c9ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9qy54arm/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYBOVHaV9rj"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uDu2nyeV91v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b90e48d-65fe-42ab-d1ff-c8cf1f77a416"
      },
      "source": [
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model()\n",
        "\n",
        "# 학습용 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/train_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/bigdata_deeplearning/data/test_data.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbggZajDob7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cc25c5-56a4-48ec-a94d-a2478550a13a"
      },
      "source": [
        "train_data['카테고리'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    1963\n",
              "3    1897\n",
              "2    1457\n",
              "1    1362\n",
              "0    1168\n",
              "Name: 카테고리, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFnKviu8WIy-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "19b495c4-2aef-4d5f-b4dd-400cbcf3802c"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>청원진행</th>\n",
              "      <th>참여인원</th>\n",
              "      <th>카테고리</th>\n",
              "      <th>청원시작</th>\n",
              "      <th>청원마감</th>\n",
              "      <th>제목</th>\n",
              "      <th>내용</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>299</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-01</td>\n",
              "      <td>2018-05-31</td>\n",
              "      <td>인천 초등생 살해범 징역 13년이라니요..</td>\n",
              "      <td>네이번 뉴스를 보다 너무 어이가 없어서 청원을 올립니다. 하루가 멀다하고 올라오는 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>1676</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-12-13</td>\n",
              "      <td>2019-01-12</td>\n",
              "      <td>우리 거북이 아이들의 미래를 부디 열어주세요</td>\n",
              "      <td>안녕하세요 4세 발달지연 아이를 키우고있는 대한민국의 평범한 어머니입니다 \\n\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>384</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-03-19</td>\n",
              "      <td>2018-04-18</td>\n",
              "      <td>단역배우자매를 성폭행한 가해자 12명을 다시 수사하고  담당경찰관을 파면해주세요</td>\n",
              "      <td>10년전의 일이고 고소를 취하한 내용이지만\\n이자매가 그일로인해 자살하고 아버지마저...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>188</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-08-26</td>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>은혜로 목사와 그 주변의 관계자들을 인터폴에 문의 하여 체포해 주세요</td>\n",
              "      <td>은혜로 목사인 신목사에게  꼬임을 당해 끌려간 사람들을 구하고 신목사와 그 주변에 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>177</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>2017-12-17</td>\n",
              "      <td>대구시 우동기 교육감을 중도에 교체할 수 있는 제도보완을 청원,제안합니다</td>\n",
              "      <td>최근 1~ 2주 사이 우동기 대구시교육감에 대한 생각을 적지 않을 수 없어 몇 자 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7842</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>195</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-09-27</td>\n",
              "      <td>2017-10-27</td>\n",
              "      <td>대입 수능 성적 정보의 구체적이고 투명한 공개를 요청 드립니다.</td>\n",
              "      <td>대입 수험생을 둔 가정에서 많은 분들이 아쉬워하는 교육과정평가원의 수능 및 모의평가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7843</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>222</td>\n",
              "      <td>4</td>\n",
              "      <td>2018-04-18</td>\n",
              "      <td>2018-05-18</td>\n",
              "      <td>국회의원전수조사</td>\n",
              "      <td>이번국회의원피기감기관지원과관련전수조사하여잘못된관행을바로잡았으면합니다이렇게해야정치개혁...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7844</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-22</td>\n",
              "      <td>2018-03-24</td>\n",
              "      <td>안전하지 않는 원전 운영허가 취소를 해 주세요</td>\n",
              "      <td>울진 한울원전 4호기는 상업운전 초기부터 심각한 전열관 손상이 있었습니다.  그리고...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7845</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>3343</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>2018-02-03</td>\n",
              "      <td>서남대학교 특별편입 반대 단국대학교 천안캠퍼스.</td>\n",
              "      <td>여러분 혹시 지금 서남대학교 폐교에대한 기사를 보셨나요?\\n\\r\\n죽전캠분들에겐 해...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7846</th>\n",
              "      <td>청원종료</td>\n",
              "      <td>145</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-03-15</td>\n",
              "      <td>2018-04-14</td>\n",
              "      <td>고 장자연님 사건이나 단역 여배우 자살 사건에 대해 청원 커트라인을 낮춰주시기를 청...</td>\n",
              "      <td>이런 귀중한 문제는 20만이 넘어가야 청원 승락되는 것에서 좀 컷트라인을 낮춰서 다...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7847 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      청원진행  ...                                                 내용\n",
              "0     청원종료  ...  네이번 뉴스를 보다 너무 어이가 없어서 청원을 올립니다. 하루가 멀다하고 올라오는 ...\n",
              "1     청원종료  ...  안녕하세요 4세 발달지연 아이를 키우고있는 대한민국의 평범한 어머니입니다 \\n\\r\\...\n",
              "2     청원종료  ...  10년전의 일이고 고소를 취하한 내용이지만\\n이자매가 그일로인해 자살하고 아버지마저...\n",
              "3     청원종료  ...  은혜로 목사인 신목사에게  꼬임을 당해 끌려간 사람들을 구하고 신목사와 그 주변에 ...\n",
              "4     청원종료  ...  최근 1~ 2주 사이 우동기 대구시교육감에 대한 생각을 적지 않을 수 없어 몇 자 ...\n",
              "...    ...  ...                                                ...\n",
              "7842  청원종료  ...  대입 수험생을 둔 가정에서 많은 분들이 아쉬워하는 교육과정평가원의 수능 및 모의평가...\n",
              "7843  청원종료  ...  이번국회의원피기감기관지원과관련전수조사하여잘못된관행을바로잡았으면합니다이렇게해야정치개혁...\n",
              "7844  청원종료  ...  울진 한울원전 4호기는 상업운전 초기부터 심각한 전열관 손상이 있었습니다.  그리고...\n",
              "7845  청원종료  ...  여러분 혹시 지금 서남대학교 폐교에대한 기사를 보셨나요?\\n\\r\\n죽전캠분들에겐 해...\n",
              "7846  청원종료  ...  이런 귀중한 문제는 20만이 넘어가야 청원 승락되는 것에서 좀 컷트라인을 낮춰서 다...\n",
              "\n",
              "[7847 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSFLvsh4qrvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5d54ce-1d13-4de3-8fe6-86ed3d8a4e37"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7847, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgmlInVOqrxH"
      },
      "source": [
        "# 라벨링된 카테고리명 매핑 ex) {0: '경제민주화', 1: '교통/건축/국토', 2: '기타',3: '농산어촌', 4: '문화/예술/체육/언론'}\n",
        "# mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "# mapping"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tnjBQyWqrzX"
      },
      "source": [
        "# Train / Test set 분리\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "# print(\"train shape is:\", len(train))\n",
        "# print(\"test shape is:\", len(test))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s9i1-TegobC"
      },
      "source": [
        "# train.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/train_data.csv', header = True, index = False)\n",
        "# test.to_csv('/content/drive/MyDrive/bigdata_deeplearning/data/test_data.csv', header = True, index = False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evkql3cLslwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3b4766-376a-4fce-e7e1-7dfbe3b47f66"
      },
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwrMvpIwslyu"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "        self.sentences = [transform(i) for i in dataset['내용']]\n",
        "        self.labels = [np.int32(i) for i in dataset['카테고리']]\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBjAZ1vBsl06"
      },
      "source": [
        "# Setting parameters\n",
        "np.random.seed(100)\n",
        "max_len = 30 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 124\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0gaiEKJsl3E"
      },
      "source": [
        "bert_train = BERTDataset(train_data, tok, max_len, True, False)\n",
        "bert_test = BERTDataset(test_data, tok, max_len, True, False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfI2d9Us0xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b053b018-df27-4f1f-9c58-0467b3766767"
      },
      "source": [
        "print(bert_train)\n",
        "print(bert_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.BERTDataset object at 0x7f0229e45750>\n",
            "<__main__.BERTDataset object at 0x7f0229f3c590>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUZpwfss01C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9698698-b7bc-45c9-a506-4061417caa3e"
      },
      "source": [
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = torch.utils.data.DataLoader(bert_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(bert_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFpr9Jrpz0wO"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 28,\n",
        "                 num_classes = 5, # softmax 사용 <- binary일 경우는 2\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_sEvyKz0yZ"
      },
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU1HjIZyz00V"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147jQgU0s03m"
      },
      "source": [
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BoKbUrvs05i"
      },
      "source": [
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()\n",
        "    return train_acc\n",
        "# /max_indices.size()[0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnfdhBTdCBV"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# for e in range(num_epochs):\n",
        "#     train_acc = 0.0\n",
        "#     # test_acc = 0.0\n",
        "#     model.train()\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length= valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "#         loss = loss_fn(out, label)\n",
        "#         loss.backward\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()  # Update learning rate schedule\n",
        "#         train_acc += calc_accuracy(out, label)\n",
        "#         if batch_id % log_interval == 0:\n",
        "#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (7847)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAtApdA8g_OA"
      },
      "source": [
        "# test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMT-As8LdIMd"
      },
      "source": [
        "# unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['제목', '카테고리']])\n",
        "# unseen_values = unseen_test.values\n",
        "# test_set = BERTDataset(unseen_values, 0, 1, tok, max_len, True, False)\n",
        "# test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3571O8GmSR_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba9170-1bd5-4e24-ec9a-fa93c3319147"
      },
      "source": [
        "test_input = torch.utils.data.DataLoader(test_data, batch_size=1, num_workers=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daha6rpBSZtD"
      },
      "source": [
        "# BERTDataset(unseen_values, tok, max_len, True, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRyY4xbkh0te"
      },
      "source": [
        "# tqdm_notebook(test_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsI9S62hoHg"
      },
      "source": [
        "# # 모델 학습 시작\n",
        "# test_acc = 0.0\n",
        "# for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "#   optimizer.zero_grad()\n",
        "#   token_ids = token_ids.long().to(device)\n",
        "#   segment_ids = segment_ids.long().to(device)\n",
        "#   valid_length= valid_length\n",
        "#   label = label.long().to(device)\n",
        "#   out = model(token_ids, valid_length, segment_ids)\n",
        "#   loss = loss_fn(out, label)\n",
        "#   loss.backward\n",
        "#   torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "#   optimizer.step()\n",
        "#   scheduler.step()  # Update learning rate schedule\n",
        "#   test_acc += calc_accuracy(out, label)\n",
        "#   if batch_id % log_interval == 0:\n",
        "#     print(\"batch id {} loss {} test acc {}\".format(batch_id+1, loss.data.cpu().numpy(), test_acc / (batch_id+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWE4YbtrNB19",
        "outputId": "5da3b588-0977-4067-add6-b049bf1a3bf8"
      },
      "source": [
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id == batch_size :\n",
        "          print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id + 1)))    \n",
        "    \n",
        "# "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/64 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 64/64 [00:13<00:00,  4.70it/s]\n",
            "  0%|          | 0/64 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 26.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:13<00:00,  4.61it/s]\n",
            "  0%|          | 0/64 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 26.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:14<00:00,  4.50it/s]\n",
            "  0%|          | 0/64 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 26.140625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:14<00:00,  4.31it/s]\n",
            "  0%|          | 0/64 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train acc 27.0625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:15<00:00,  4.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train acc 26.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "8a0284cc2e234434a24b856a0c8cfcd4",
            "08c07aeff70044299585bfd7c4d7fd14",
            "95b4543cbabd42d591fae4aa388ce49e",
            "f693c537590a41c8ba33a560ac085374",
            "9508e3a861b04e5f9adf6610f71e9b23",
            "df8964880c4a4e4a9ba03998ab8ee25f",
            "54b1b5e0f8264355b4437d25e880552e",
            "b2b774c87f03459cbdc1330b6bbcdd8c"
          ]
        },
        "id": "KLZZddjvPFjb",
        "outputId": "0f03d957-bf8f-4339-cec0-94cd591e0f2a"
      },
      "source": [
        "model.eval() # 평가 모드로 변경\n",
        "test_acc = 0.0\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  label = label.long().to(device)\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  test_acc += calc_accuracy(out, label)\n",
        "  print(\"test acc {}\".format(test_acc / (batch_id+1)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a0284cc2e234434a24b856a0c8cfcd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc 33.0\n",
            "test acc 37.5\n",
            "test acc 36.0\n",
            "test acc 32.75\n",
            "test acc 31.2\n",
            "test acc 31.333333333333332\n",
            "test acc 31.142857142857142\n",
            "test acc 30.75\n",
            "test acc 30.77777777777778\n",
            "test acc 30.6\n",
            "test acc 29.90909090909091\n",
            "test acc 29.75\n",
            "test acc 31.076923076923077\n",
            "test acc 31.285714285714285\n",
            "test acc 31.133333333333333\n",
            "test acc 30.5625\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}